{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install julep"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7YvegBbYywy",
        "outputId": "65c7d384-0c1f-45c9-c3e0-6fd675b5bf85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting julep\n",
            "  Downloading julep-2.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from julep) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from julep) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from julep) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from julep) (2.11.7)\n",
            "Collecting python-dotenv<1.1,>=1.0 (from julep)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel-yaml<0.19,>=0.18.6 (from julep)\n",
            "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from julep) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from julep) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->julep) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->julep) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->julep) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->julep) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->julep) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->julep) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->julep) (0.4.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml<0.19,>=0.18.6->julep)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading julep-2.19.2-py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.3/271.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, python-dotenv, ruamel-yaml, julep\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.1.1\n",
            "    Uninstalling python-dotenv-1.1.1:\n",
            "      Successfully uninstalled python-dotenv-1.1.1\n",
            "Successfully installed julep-2.19.2 python-dotenv-1.0.1 ruamel-yaml-0.18.15 ruamel.yaml.clib-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "API_KEY = config['julep']['api_key']\n",
        "project_name = 'hiringAssistant___'"
      ],
      "metadata": {
        "id": "0rkeZ0fKDVWu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4) SAMPLE INPUTS\n",
        "# =========================\n",
        "criteria = {\n",
        "    \"role\": \"Senior Backend Engineer\",\n",
        "    \"must_haves\": [\"Python\", \"Distributed systems\", \"PostgreSQL\"],\n",
        "    \"nice_to_haves\": [\"Kubernetes\", \"AWS\", \"gRPC\"],\n",
        "    \"weights\": {\"must_haves\": 0.6, \"nice_to_haves\": 0.2, \"experience\": 0.2},\n",
        "    \"disqualifiers\": [],\n",
        "}\n",
        "resumes = [\n",
        "    {\"name\": \"Alice Smith\", \"text\": \"Python, FastAPI, PostgreSQL, 5y backend, AWS, K8s, microservices...\"},\n",
        "    {\"name\": \"Bob Lee\", \"text\": \"Java, Spring, MySQL, some Python, 3y backend, Kafka...\"},\n",
        "    {\"name\": \"Carmen Diaz\", \"text\": \"Python, Django, Postgres, 7y backend, distributed systems, gRPC, AWS...\"},\n",
        "]\n",
        "n = 2\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 4) SAMPLE INPUTS\n",
        "# =========================\n",
        "# criteria = {\n",
        "#     \"role\": \"Dancer\",\n",
        "#     \"must_haves\": [\"Dancing\", \"Singing\", \"acting\"],\n",
        "#     \"nice_to_haves\": [\"Acting\"],\n",
        "#     \"weights\": {\"must_haves\": 0.6, \"nice_to_haves\": 0.2, \"experience\": 0.2},\n",
        "#     \"disqualifiers\": [],\n",
        "# }\n",
        "# resumes = [\n",
        "#     {\"name\": \"Alice Smith\", \"text\": \"Dancing, Singing, acting...\"},\n",
        "#     {\"name\": \"Bob Lee\", \"text\": \"acting, dancing, MySQL, some Python, 3y backend, Kafka...\"},\n",
        "#     {\"name\": \"Carmen Diaz\", \"text\": \"Python, Django, acting, 7y backend, distributed systems, gRPC, AWS...\"},\n",
        "# ]\n",
        "# n = 2"
      ],
      "metadata": {
        "id": "ipDJk8EidofL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recruitment_assistant_multi.py\n",
        "import os, time, json\n",
        "from julep import Julep\n",
        "\n",
        "client = Julep(api_key=API_KEY)\n",
        "\n",
        "# =========================\n",
        "# 0) MULTI-AGENT SETUP\n",
        "# =========================\n",
        "\n",
        "# A) Extractor — focused on conservative evidence extraction\n",
        "extractor = client.agents.create(\n",
        "    name=\"ExtractorAgent\",\n",
        "    about=\"Extracts structured evidence from resumes: skills, experience, education, projects.\",\n",
        "    instructions=\"Be precise and conservative. Do not invent facts.\",\n",
        "    project=\"default\",\n",
        ")\n",
        "print(\"ExtractorAgent:\", extractor.id)\n",
        "\n",
        "# B) Orchestrator — coordinates scoring/merging; stricter JSON\n",
        "\n",
        "orchestrator = client.agents.create(\n",
        "    name=\"OrchestratorAgent\",\n",
        "    about=\"Scores & ranks candidates, merges results to final JSON.\",\n",
        "    instructions=\"Return valid JSON. Be deterministic and auditable.\",\n",
        "    project=\"default\",\n",
        "    default_settings={\n",
        "        \"temperature\": 0.2,\n",
        "        \"instructions\": \"Return valid JSON only; do not invent facts.\",\n",
        "        \"response_format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"json_schema\": {\n",
        "                \"name\": \"RecruitmentResult\",\n",
        "                \"schema\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"ranked\": {\n",
        "                            \"type\": \"array\",\n",
        "                            \"items\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"properties\": {\n",
        "                                    \"name\": {\"type\": \"string\"},\n",
        "                                    \"score\": {\"type\": \"number\"},\n",
        "                                    \"rationale\": {\"type\": \"string\", \"maxLength\": 240}\n",
        "                                },\n",
        "                                \"required\": [\"name\", \"score\", \"rationale\"]\n",
        "                            }\n",
        "                        },\n",
        "                        \"top_n_questions\": {\n",
        "                            \"type\": \"array\",\n",
        "                            \"items\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"properties\": {\n",
        "                                    \"name\": {\"type\": \"string\"},\n",
        "                                    \"questions\": {\n",
        "                                        \"type\": \"array\",\n",
        "                                        \"items\": {\"type\": \"string\", \"maxLength\": 200},\n",
        "                                        \"maxItems\": 5, \"minItems\": 1\n",
        "                                    }\n",
        "                                },\n",
        "                                \"required\": [\"name\", \"questions\"]\n",
        "                            }\n",
        "                        },\n",
        "                        \"evidence\": {\n",
        "                            \"type\": \"array\",\n",
        "                            \"items\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"properties\": {\n",
        "                                    \"name\": {\"type\": \"string\"},\n",
        "                                    \"skills\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                                    \"experience\": {\n",
        "                                        \"type\": \"array\",\n",
        "                                        \"items\": {\n",
        "                                            \"type\": \"object\",\n",
        "                                            \"properties\": {\n",
        "                                                \"role\": {\"type\": \"string\"},\n",
        "                                                \"years\": {\"type\": \"number\"}\n",
        "                                            },\n",
        "                                            \"required\": [\"role\"]\n",
        "                                        }\n",
        "                                    },\n",
        "                                    \"education\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                                    \"projects\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
        "                                },\n",
        "                                \"required\": [\"name\"]\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"ranked\", \"top_n_questions\", \"evidence\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "print(\"OrchestratorAgent:\", orchestrator.id)\n",
        "\n",
        "# C) Interviewer — crafts tailored questions\n",
        "interviewer = client.agents.create(\n",
        "    name=\"InterviewerAgent\",\n",
        "    about=\"Writes tailored interview questions that reference the candidate's background.\",\n",
        "    instructions=\"Ask concrete, specific, and technical questions tied to their evidence. No fluff.\",\n",
        "    project=\"default\",\n",
        ")\n",
        "interviewer = client.agents.update(interviewer.id, default_settings={\"temperature\": 0.3})\n",
        "print(\"InterviewerAgent:\", interviewer.id)\n",
        "\n",
        "\n",
        "\n",
        "# 1) FUNCTION TOOLS (LOCAL)\n",
        "\n",
        "def normalize_term(s):\n",
        "    mapping = {\n",
        "        \"postgres\": \"PostgreSQL\",\n",
        "        \"postgresql\": \"PostgreSQL\",\n",
        "        \"postgre\": \"PostgreSQL\",\n",
        "        \"k8s\": \"Kubernetes\",\n",
        "        \"js\": \"JavaScript\",\n",
        "        \"ts\": \"TypeScript\",\n",
        "        \"node\": \"Node.js\",\n",
        "    }\n",
        "    key = (s or \"\").strip().lower()\n",
        "    return mapping.get(key, s)\n",
        "import re, json\n",
        "\n",
        "def _parse_evidence_obj(evidence_json):\n",
        "    # Accept dict/list directly\n",
        "    if isinstance(evidence_json, (dict, list)):\n",
        "        return evidence_json\n",
        "    if not isinstance(evidence_json, str):\n",
        "        return {\"evidence\": []}\n",
        "\n",
        "    s = evidence_json.strip()\n",
        "\n",
        "    # Strip ```json ... ``` fences if present\n",
        "    if s.startswith(\"```\"):\n",
        "        s = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", s, flags=re.S)\n",
        "\n",
        "    # Try strict JSON first\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        # As a fallback, extract the first {...} block from the string\n",
        "        m = re.search(r\"\\{.*\\}\\s*$\", s, flags=re.S)\n",
        "        if m:\n",
        "            try:\n",
        "                return json.loads(m.group(0))\n",
        "            except Exception:\n",
        "                pass\n",
        "        return {\"evidence\": []}\n",
        "\n",
        "def compute_scores_locally(criteria, evidence_json, n):\n",
        "    evidence_obj = _parse_evidence_obj(evidence_json)\n",
        "    ev_list = evidence_obj.get(\"evidence\", []) if isinstance(evidence_obj, dict) else (evidence_obj or [])\n",
        "    must = set(normalize_term(x) for x in criteria.get(\"must_haves\", []))\n",
        "    nice = set(normalize_term(x) for x in criteria.get(\"nice_to_haves\", []))\n",
        "    weights = criteria.get(\"weights\", {\"must_haves\": 0.6, \"nice_to_haves\": 0.2, \"experience\": 0.2})\n",
        "\n",
        "    ranked = []\n",
        "    for item in ev_list:\n",
        "        name = item.get(\"name\") or \"Unknown\"\n",
        "        skills = set(normalize_term(s) for s in item.get(\"skills\", []))\n",
        "\n",
        "        # simple experience tally\n",
        "        exp_years = 0.0\n",
        "        for e in item.get(\"experience\", []):\n",
        "            try:\n",
        "                exp_years += float(e.get(\"years\", 0))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # coverage\n",
        "        must_cov = sum(1 for m in must if any(m.lower() == s.lower() for s in skills))\n",
        "        must_need = max(1, len(must))\n",
        "        must_score = must_cov / must_need\n",
        "\n",
        "        nice_cov = sum(1 for h in nice if any(h.lower() == s.lower() for s in skills))\n",
        "        nice_need = max(1, len(nice))\n",
        "        nice_score = nice_cov / nice_need\n",
        "\n",
        "        # cap at 8 years for normalization\n",
        "        exp_score = min(exp_years, 8.0) / 8.0\n",
        "\n",
        "        score = (\n",
        "            weights.get(\"must_haves\", 0.6) * must_score +\n",
        "            weights.get(\"nice_to_haves\", 0.2) * nice_score +\n",
        "            weights.get(\"experience\", 0.2) * exp_score\n",
        "        )\n",
        "\n",
        "        rationale_bits = []\n",
        "        if len(must) > 0:\n",
        "            rationale_bits.append(f\"Must-haves: {must_cov}/{len(must)}\")\n",
        "        if len(nice) > 0:\n",
        "            rationale_bits.append(f\"Nice: {nice_cov}/{len(nice)}\")\n",
        "        rationale_bits.append(f\"Exp: {exp_years:.0f}y\")\n",
        "        ranked.append({\"name\": name, \"score\": round(score, 4), \"rationale\": \"; \".join(rationale_bits)})\n",
        "    ranked.sort(key=lambda r: r[\"score\"], reverse=True)\n",
        "    k = max(1, int(n))\n",
        "    top_ranked = ranked[:k]\n",
        "    top_n_names = [r[\"name\"] for r in top_ranked]\n",
        "\n",
        "    # filter evidence to top-N, in the same order as ranking\n",
        "    by_name = {e.get(\"name\"): e for e in ev_list if isinstance(e, dict) and e.get(\"name\")}\n",
        "    top_evidence = [by_name[name] for name in top_n_names if name in by_name]\n",
        "\n",
        "    return {\"ranked\": top_ranked, \"top_n_names\": top_n_names, \"evidence\": top_evidence}\n",
        "\n",
        "def dedupe_questions_locally(questions_json):\n",
        "    # Input is a JSON str or dict with key \"top_n_questions\": [{name, questions: [...]},{\"...\"}]\n",
        "    if isinstance(questions_json, str):\n",
        "        try:\n",
        "            qobj = json.loads(questions_json)\n",
        "        except Exception:\n",
        "            qobj = {}\n",
        "    else:\n",
        "        qobj = questions_json or {}\n",
        "\n",
        "    items = qobj.get(\"top_n_questions\", [])\n",
        "    cleaned = []\n",
        "    for item in items:\n",
        "        name = item.get(\"name\", \"Unknown\")\n",
        "        qs = [q.strip() for q in item.get(\"questions\", []) if isinstance(q, str)]\n",
        "        # simple de-dup while preserving order\n",
        "        seen = set()\n",
        "        uniq = []\n",
        "        for q in qs:\n",
        "            key = q.lower()\n",
        "            if key not in seen and q:\n",
        "                uniq.append(q)\n",
        "                seen.add(key)\n",
        "        cleaned.append({\"name\": name, \"questions\": uniq[:5]})\n",
        "    return {\"top_n_questions\": cleaned}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx1AKmqWcjP8",
        "outputId": "b1297330-1e4c-4ead-e663-2deddaf24985"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExtractorAgent: 068ac345-3b4d-7599-8000-a80432a4404f\n",
            "OrchestratorAgent: 068ac345-3e52-75bd-8000-f17cfa0be3c9\n",
            "InterviewerAgent: 068ac345-415f-7431-8000-cfd9ca725bf8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===================================\n",
        "# 2) TASK A — EXTRACT EVIDENCE (LLM)\n",
        "# ===================================\n",
        "extract_task = {\n",
        "    \"name\": \"extract_evidence_task\",\n",
        "    \"description\": \"Extract structured evidence from resumes\",\n",
        "    \"input_schema\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\"resumes\"],\n",
        "        \"properties\": {\"resumes\": {\"type\": \"array\"}}\n",
        "    },\n",
        "    \"main\": [\n",
        "        {\n",
        "            \"prompt\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"Extract ONLY structured evidence from the resumes. \"\n",
        "                        \"Do not score. Do not invent facts.\\n\\n\"\n",
        "                        \"Return JSON with one key: evidence. \"\n",
        "                        \"Each item includes:\\n\"\n",
        "                        \"- name: string\\n\"\n",
        "                        \"- skills: array of strings\\n\"\n",
        "                        \"- experience: array of objects with fields 'role' (string) and 'years' (number)\\n\"\n",
        "                        \"- education: array of strings\\n\"\n",
        "                        \"- projects: array of strings\\n\"\n",
        "                        \"Return JSON ONLY.\"\n",
        "                    )\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": \"$ f'''Resumes: {steps[0].input.resumes}'''\"},\n",
        "            ],\n",
        "            \"unwrap\": True,\n",
        "            \"save_as\": \"evidence_json\",\n",
        "        },\n",
        "        {\"return\": {\"evidence_json\": \"$ steps[0].output\"}},\n",
        "    ],\n",
        "}\n",
        "extract_task_obj = client.tasks.create(agent_id=extractor.id, **extract_task)\n",
        "print(\"Task A ready:\", extract_task_obj.id, extract_task_obj.name)\n",
        "\n",
        "# ==========================================================\n",
        "# 3) TASK B — SCORE, QUESTIONS, DEDUPE, MERGE (LLM + TOOLS)\n",
        "# ==========================================================\n",
        "rank_task = {\n",
        "    \"name\": \"rank_and_questions_task\",\n",
        "    \"description\": \"Score & rank via tool; draft questions; dedupe via tool; merge final JSON.\",\n",
        "    \"tools\": [\n",
        "        {\n",
        "            \"name\": \"compute_scores\",\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"description\": \"Compute scores and ranking using criteria and extracted evidence.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"criteria\": {\"type\": \"object\"},\n",
        "                        \"evidence\": {\"type\": \"object\"},\n",
        "                        \"n\": {\"type\": \"integer\", \"minimum\": 1}\n",
        "                    },\n",
        "                    \"required\": [\"criteria\", \"evidence\", \"n\"],\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"dedupe_questions\",\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"description\": \"Deduplicate and trim interview questions per candidate to 5.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"questions\": {\"type\": \"object\"}\n",
        "                    },\n",
        "                    \"required\": [\"questions\"],\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "    ],\n",
        "    \"input_schema\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\"criteria\", \"evidence_json\", \"n\"],\n",
        "        \"properties\": {\n",
        "            \"criteria\": {\"type\": \"object\"},\n",
        "            \"evidence_json\": {\"type\": \"string\"},  # string from Task A\n",
        "            \"n\": {\"type\": \"integer\", \"minimum\": 1}\n",
        "        }\n",
        "    },\n",
        "    \"main\": [\n",
        "        # Step 0 — Call compute_scores (awaiting_input; resume from client)\n",
        "        {\n",
        "            \"tool\": \"compute_scores\",\n",
        "            \"arguments\": {\n",
        "                \"criteria\": \"$ steps[0].input.criteria\",\n",
        "                \"evidence\": \"$ steps[0].input.evidence_json\",\n",
        "                \"n\": \"$ steps[0].input.n\",\n",
        "            },\n",
        "            \"save_as\": \"scored\",\n",
        "        },\n",
        "\n",
        "        # Step 1 — Draft tailored questions (InterviewerAgent style via instructions in content)\n",
        "        {\n",
        "            \"prompt\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"You are InterviewerAgent. Write tailored interview questions tied to each candidate's background. \"\n",
        "                        \"Ask about specific technologies, projects, and experience they actually have. Be concrete. \"\n",
        "                        \"Return JSON ONLY with key top_n_questions (an array of objects; each object has fields 'name' (string) and 'questions' (array of strings)).\"\n",
        "\n",
        "                    )\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": \"Evidence JSON:\"},\n",
        "                {\"role\": \"user\", \"content\": \"$ f'''{steps[0].input.evidence_json}'''\"},\n",
        "                {\"role\": \"user\", \"content\": \"Scoring result (ranked list & top_n_names):\"},\n",
        "                {\"role\": \"user\", \"content\": \"$ f'''{steps[0].output}'''\"},\n",
        "            ],\n",
        "            \"unwrap\": True,\n",
        "            \"save_as\": \"questions_json\",\n",
        "        },\n",
        "\n",
        "        # Step 2 — Dedupe/clean questions via tool (awaiting_input; resume from client)\n",
        "        {\n",
        "            \"tool\": \"dedupe_questions\",\n",
        "            \"arguments\": {\n",
        "                \"questions\": \"$ steps[1].output\"\n",
        "            },\n",
        "            \"save_as\": \"questions_clean\",\n",
        "        },\n",
        "\n",
        "        # Step 3 — Merge into final object\n",
        "        {\n",
        "          \"prompt\": [\n",
        "            {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": (\n",
        "                \"You are InterviewerAgent. Write tailored interview questions tied to each candidate's background. \"\n",
        "                \"Ask about specific technologies, projects, and experience they actually have. Be concrete. \"\n",
        "                \"Return JSON ONLY with key top_n_questions (an array of objects; each object has fields 'name' (string) and 'questions' (array of strings)).\"\n",
        "              )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"Evidence JSON:\"},\n",
        "            {\"role\": \"user\", \"content\": \"$ f'''{steps[0].input.evidence_json}'''\"},\n",
        "            {\"role\": \"user\", \"content\": \"Scoring result (ranked list & top_n_names):\"},\n",
        "            {\"role\": \"user\", \"content\": \"$ f'''{steps[0].output}'''\"},\n",
        "          ],\n",
        "          \"unwrap\": True,\n",
        "          \"save_as\": \"questions_json\",\n",
        "        },\n",
        "\n",
        "        {\"return\": {\"result_json\": \"$ steps[3].output\"}},\n",
        "    ],\n",
        "}\n",
        "rank_task_obj = client.tasks.create(agent_id=orchestrator.id, **rank_task)\n",
        "print(\"Task B ready:\", rank_task_obj.id, rank_task_obj.name)\n",
        "\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 5) RUN — EXECUTE TASK A\n",
        "# =========================\n",
        "def exec_until_done(task_id, task_input, tool_handlers=None):\n",
        "    exe = client.executions.create(task_id=task_id, input=task_input)\n",
        "    print(\"Execution:\", exe.id)\n",
        "    while True:\n",
        "        exe = client.executions.get(exe.id)\n",
        "        print(\"Status:\", exe.status)\n",
        "        if exe.status == \"awaiting_input\":\n",
        "            # we expect a function tool pause\n",
        "            if not tool_handlers:\n",
        "                raise RuntimeError(\"No tool_handlers provided for awaiting_input step.\")\n",
        "            # last saved outputs are in exe.output (dict of save_as keys if exposed)\n",
        "            last_out = getattr(exe, \"output\", {}) or {}\n",
        "            # Simple routing based on which step we just hit:\n",
        "            if \"scored\" not in last_out and \"questions_clean\" not in last_out:\n",
        "                # likely waiting on first tool in Task B: compute_scores\n",
        "                handler = tool_handlers.get(\"compute_scores\")\n",
        "                payload = handler()\n",
        "            elif \"scored\" in last_out and \"questions_clean\" not in last_out:\n",
        "                # waiting on dedupe_questions step\n",
        "                handler = tool_handlers.get(\"dedupe_questions\")\n",
        "                payload = handler()\n",
        "            else:\n",
        "                # fallback\n",
        "                raise RuntimeError(\"Unexpected awaiting_input stage; cannot route tool handler.\")\n",
        "            client.executions.change_status(execution_id=exe.id, status=\"running\", input=payload)\n",
        "            print(\"Provided tool result and resumed.\")\n",
        "        elif exe.status in (\"succeeded\", \"failed\", \"cancelled\"):\n",
        "            break\n",
        "        time.sleep(1)\n",
        "    print(\"Final status:\", exe.status)\n",
        "    return exe\n",
        "\n",
        "# Execute Task A (Extractor)\n",
        "exe_a = exec_until_done(\n",
        "    extract_task_obj.id,\n",
        "    {\"resumes\": resumes},\n",
        ")\n",
        "\n",
        "# Collect evidence_json (string)\n",
        "output_a = getattr(exe_a, \"output\", {}) or {}\n",
        "evidence_json = output_a.get(\"evidence_json\") or \"\"\n",
        "# =========================\n",
        "# 6) RUN — EXECUTE TASK B (robust)\n",
        "# =========================\n",
        "def safe_json_loads(maybe_str):\n",
        "    if isinstance(maybe_str, str):\n",
        "        try:\n",
        "            return json.loads(maybe_str)\n",
        "        except Exception:\n",
        "            return None\n",
        "    return maybe_str if isinstance(maybe_str, dict) else None\n",
        "\n",
        "def print_failure(exe):\n",
        "    print(\"Final status:\", exe.status)\n",
        "    print(\"Error:\", getattr(exe, \"error\", None))\n",
        "    print(\"Raw output:\", getattr(exe, \"output\", None))\n",
        "\n",
        "def tool_handler_compute_scores():\n",
        "    return compute_scores_locally(criteria, evidence_json, n)\n",
        "\n",
        "def tool_handler_dedupe_questions(current_exe_id):\n",
        "    latest = client.executions.get(current_exe_id)\n",
        "    latest_out = getattr(latest, \"output\", {}) or {}\n",
        "    # \"questions_json\" might be a dict or a stringified JSON\n",
        "    q_payload = latest_out.get(\"questions_json\")\n",
        "    q_obj = safe_json_loads(q_payload) or {\"top_n_questions\": []}\n",
        "    return dedupe_questions_locally(q_obj)\n",
        "\n",
        "# Start Task B\n",
        "exe_b = client.executions.create(\n",
        "    task_id=rank_task_obj.id,\n",
        "    input={\"criteria\": criteria, \"evidence_json\": evidence_json, \"n\": n},\n",
        ")\n",
        "print(\"Execution (Task B):\", exe_b.id)\n",
        "\n",
        "while True:\n",
        "    exe_b = client.executions.get(exe_b.id)\n",
        "    print(\"Status B:\", exe_b.status)\n",
        "\n",
        "    if exe_b.status == \"awaiting_input\":\n",
        "      outb = getattr(exe_b, \"output\", {}) or {}\n",
        "\n",
        "      # If we already have questions_json but not questions_clean -> run dedupe\n",
        "      if \"questions_json\" in outb and \"questions_clean\" not in outb:\n",
        "          payload = tool_handler_dedupe_questions(exe_b.id)\n",
        "          client.executions.change_status(execution_id=exe_b.id, status=\"running\", input=payload)\n",
        "          print(\"dedupe_questions -> resumed.\")\n",
        "\n",
        "      # If we don't even have 'scored' yet -> first pause is compute_scores\n",
        "      elif \"scored\" not in outb:\n",
        "          payload = tool_handler_compute_scores()\n",
        "          client.executions.change_status(execution_id=exe_b.id, status=\"running\", input=payload)\n",
        "          print(\"compute_scores -> resumed.\")\n",
        "\n",
        "      else:\n",
        "          # We have 'scored' but no 'questions_json' yet; that's a prompt step—just keep polling\n",
        "          print(\"Waiting for questions_json to be produced...\")\n",
        "\n",
        "    elif exe_b.status in (\"succeeded\", \"failed\", \"cancelled\"):\n",
        "        break\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "# =========================\n",
        "# 7) RESULT (robust)\n",
        "# =========================\n",
        "if exe_b.status != \"succeeded\":\n",
        "    print_failure(exe_b)\n",
        "else:\n",
        "    out_b = getattr(exe_b, \"output\", None)\n",
        "\n",
        "    # Case A: output is a dict with result_json (string)\n",
        "    if isinstance(out_b, dict) and \"result_json\" in out_b:\n",
        "        result_json = out_b[\"result_json\"]\n",
        "        parsed = safe_json_loads(result_json)\n",
        "        if parsed:\n",
        "            print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
        "        else:\n",
        "            print(\"Raw result_json:\", result_json)\n",
        "\n",
        "    # Case B: output is already the final JSON string (no result_json wrapper)\n",
        "    elif isinstance(out_b, str):\n",
        "        parsed = safe_json_loads(out_b)\n",
        "        if parsed:\n",
        "            print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
        "        else:\n",
        "            print(\"Raw output string:\", out_b)\n",
        "\n",
        "    # Case C: output is a dict without result_json (rare), print it\n",
        "    else:\n",
        "        print(\"Raw output object:\", out_b)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9KG90ViRK5a",
        "outputId": "3e018249-0734-4f8e-8697-e22da70f6f54"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task A ready: 068ac345-4784-7dba-8000-3a55750f3413 extract_evidence_task\n",
            "Task B ready: 068ac345-4a5d-7fb9-8000-2694ba3c963e rank_and_questions_task\n",
            "Execution: 068ac345-4f44-7dd4-8000-e253b2c5957d\n",
            "Status: queued\n",
            "Status: starting\n",
            "Status: starting\n",
            "Status: succeeded\n",
            "Final status: succeeded\n",
            "Execution (Task B): 068ac345-8fe8-77fa-8000-1b53f3bc71f8\n",
            "Status B: queued\n",
            "Status B: awaiting_input\n",
            "compute_scores -> resumed.\n",
            "Status B: running\n",
            "Status B: running\n",
            "Status B: running\n",
            "Status B: running\n",
            "Status B: running\n",
            "Status B: running\n",
            "Status B: awaiting_input\n",
            "compute_scores -> resumed.\n",
            "Status B: running\n",
            "Status B: succeeded\n",
            "{\n",
            "  \"ranked\": [\n",
            "    {\n",
            "      \"name\": \"Carmen Diaz\",\n",
            "      \"score\": 0.9083,\n",
            "      \"rationale\": \"Must-haves: 3/3; Nice: 2/3; Exp: 7y\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Alice Smith\",\n",
            "      \"score\": 0.6583,\n",
            "      \"rationale\": \"Must-haves: 2/3; Nice: 2/3; Exp: 5y\"\n",
            "    }\n",
            "  ],\n",
            "  \"evidence\": [\n",
            "    {\n",
            "      \"name\": \"Carmen Diaz\",\n",
            "      \"skills\": [\n",
            "        \"Python\",\n",
            "        \"Django\",\n",
            "        \"Postgres\",\n",
            "        \"distributed systems\",\n",
            "        \"gRPC\",\n",
            "        \"AWS\"\n",
            "      ],\n",
            "      \"projects\": [],\n",
            "      \"education\": [],\n",
            "      \"experience\": [\n",
            "        {\n",
            "          \"role\": \"backend\",\n",
            "          \"years\": 7\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Alice Smith\",\n",
            "      \"skills\": [\n",
            "        \"Python\",\n",
            "        \"FastAPI\",\n",
            "        \"PostgreSQL\",\n",
            "        \"AWS\",\n",
            "        \"K8s\",\n",
            "        \"microservices\"\n",
            "      ],\n",
            "      \"projects\": [],\n",
            "      \"education\": [],\n",
            "      \"experience\": [\n",
            "        {\n",
            "          \"role\": \"backend\",\n",
            "          \"years\": 5\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"top_n_questions\": [\n",
            "    {\n",
            "      \"name\": \"Carmen Diaz\",\n",
            "      \"questions\": [\n",
            "        \"Can you describe your experience with Django and how you've used it in your projects?\",\n",
            "        \"How have you implemented distributed systems in your previous roles?\",\n",
            "        \"Can you provide an example of how you've used gRPC in a project?\",\n",
            "        \"What are some challenges you've faced when working with AWS, and how did you overcome them?\",\n",
            "        \"How do you ensure the scalability and reliability of the systems you design?\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Alice Smith\",\n",
            "      \"questions\": [\n",
            "        \"Can you discuss a project where you used FastAPI and the benefits it provided?\",\n",
            "        \"How have you utilized Kubernetes (K8s) in managing microservices?\",\n",
            "        \"Can you explain your experience with PostgreSQL and any optimization techniques you've employed?\",\n",
            "        \"What strategies do you use to manage and deploy applications on AWS?\",\n",
            "        \"How do you approach designing microservices architecture?\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OiHOok-IqvJt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}